{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXkuQhJyeUSE"
   },
   "source": [
    "# Spam Detection using Transformers\n",
    "\n",
    "This notebook demonstrates a basic spam detection system using **BERT** for text classification.\n",
    "\n",
    "> Note: Spam detection can also be done using simpler ML algorithms like logistic regression or Naive Bayes, which would be faster for small datasets. This example is mainly to understand how **Transformers work** for text classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuTK4xHvpyyY"
   },
   "source": [
    "### 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "sLTZe0DmpQCA",
    "outputId": "4af91dee-ac40-4cd0-8645-4bd3511d29c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbB6bGTap4Dt"
   },
   "source": [
    "### 2. Load Dataset (SMS Spam Collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "470748ae554a4628b80a65b34048041e",
      "107dce8be242430bb531b6667e92e9ce",
      "99e09be4fb5143699036b6de11816f7b",
      "6751084e5cd1408aae63e0c72b964c09",
      "a384608678d24c29898a66f03cae74f0",
      "8447fd2d042e4aa5a4e6185e9dbd3665",
      "a5a31f66c05b432898faab2d4b517eb1",
      "ce799db410244859aa4c3ac38ba3cd1e",
      "cb4bd5d706094988ab67fc4db60c6e5f",
      "a29d2264e1104759af4255a13c75d287",
      "aa6f96b173e54c22b21dcf464a7148e1",
      "75b98dd2c0774c7c8b26fd347451c47e",
      "d6121bb3bacf4aceaeb1bd90230c7720",
      "1e37328754494e6292f8c331b46e7222",
      "c7c7ae2f677b447d97b67fcf1839c726",
      "5ef4c5bf2e86474e8db3f692be3cfb59",
      "677f37cde6d94462860d240f04486c52",
      "d6064699deb645f59f3486f6ef81e5a6",
      "5a5b04769993404987e285781050c93d",
      "dd5cac62403343d095a263a4e6632054",
      "5dbdc6577a534e75a66d4676f9778886",
      "0325f9a8cf534854840667f579c9df18",
      "2e25ede3f12d4032bc9b653ff31558b7",
      "94ceeba7c788456e8f3e792f0de6189e",
      "ff2a8eba5e4948df9091119c5c056f0a",
      "1ca4334a9ad74ecc91cd1193e14779a4",
      "8eec0e1c39b845b0ae32a4617b6ac281",
      "96941d66110e430e91bbdba077c88357",
      "f989b2e6ba5644bc90869d435d4521f1",
      "6c726ad674024300a7c00bd95495e897",
      "4621294b681b4ff7b4574bb50a17a911",
      "e80b7c2825c7401eaeeb6b5636962663",
      "43e8e76874244487a41ce96022f24798"
     ]
    },
    "id": "yM17zvX3pgY8",
    "outputId": "90c03424-4d69-4324-b739-8c5e24fb68f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470748ae554a4628b80a65b34048041e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b98dd2c0774c7c8b26fd347451c47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e25ede3f12d4032bc9b653ff31558b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sms', 'label'],\n",
      "        num_rows: 5574\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"sms_spam\")\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pl8HSsp1qESy"
   },
   "source": [
    "### 3. Preprocess (Tokenize with BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "2e08ece9397e44ce8833b0ed5a4adae8",
      "9e115770ec8f490ea3268be39851b8c6",
      "aea8886ceeb2431fb127c80f165bfda7",
      "4740a50b569c45b1bfa8dcd37f25fa8c",
      "869373d21de44c57806ecb5a993dddc8",
      "047995fcf6a6460187f32c5ad630f07d",
      "ea5b9eb0a8f6488186dd08cdaa0de1b5",
      "d96e6a28b5e3431f960ca60f452a6a7a",
      "646e377470214b29ab1085e4c4a53474",
      "8d43f120f9de4078afe901003c966821",
      "f85ddba0755d49ec830ed29bbc1f8d95",
      "b220546152ff41e5a1800d9b74eff05f",
      "2ce3c40d6f1e451381232296a1f8f678",
      "6f0f7014194040f3aa7cb16b3a7ec6a8",
      "24cd71619b2b4d78ab28fba2a76797ee",
      "788e8f53dcd941e8aa7a40ee2644b43d",
      "12def5393d024f92a3cadcf058dd6cd3",
      "7ff0b990744a471f9f5c0f9b53c2b2d3",
      "15694ec32ab543cfa9997789b7b73cff",
      "1d92dc7087284f6dad40c0f840803dad",
      "6f3bbe2a18e84773a9b4994104948841",
      "94bce5b04cd34bd3bf0f1f22b79a7d8f",
      "6347c346c4294bafa4cd7791eaf637a0",
      "b9597ccb58bf47c59fc7b36f4c82db82",
      "c6b5c0a33a3d4d37acd3a828128309de",
      "b39f9f4bcd5f43848aa256d267d9ca54",
      "79c331ab5e4048838b683df0d582a800",
      "6c33bbe9e356483b8d713e9675826164",
      "a1fee5647afb40fbb7ffbe63c2f92ff8",
      "3b636b6d20694e029e3a6ca7548a9659",
      "e1536f44242e4a13afcfbbbe98abe735",
      "6398af12dd5f4703936fe0c0b9edaf25",
      "6d7bb40591784160bd5baca34d5545ff",
      "ef1ae7f17f8c46a281012a9593899dd6",
      "bf4d83a2953c44d58525d91a2a97c869",
      "a9db2c31045548d6b52ee0b5ffd1b7bf",
      "d2ff7fe2cce14593b8676e4b9d62a02f",
      "9e76b9a2b5b94b08a55ad137a8d88f9b",
      "f56bebd63cf44847a0c30a5b3e394a17",
      "3d4a88399e414f80ad09b5c6d742eae0",
      "31062afe8b1e49079cec9c938f8d9520",
      "df34978b4651491bb941951aac522d89",
      "201f3520144c4665a7158ab36faef2c8",
      "b600d57cd06e46acb15e7d79f54e00ca"
     ]
    },
    "id": "LTwM6X88p7e7",
    "outputId": "0807b3f4-8520-4eed-a234-af3e69b6d4f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e08ece9397e44ce8833b0ed5a4adae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b220546152ff41e5a1800d9b74eff05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6347c346c4294bafa4cd7791eaf637a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1ae7f17f8c46a281012a9593899dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"sms\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucsvwzfnqaOU"
   },
   "source": [
    "### 4. Prepare Data for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bBTJFFp4qNQD"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_loader = DataLoader(tokenized_dataset[\"train\"], batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCR597znqkh6"
   },
   "source": [
    "### 5. Load Pretrained BERT for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3DKTiWqqeXN",
    "outputId": "efa17a22-7319-46b8-b90c-22d0ab76221b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load pretrained BERT with classification head (2 classes: ham/spam)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-imdb\") - for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdzHR3_TrTkq"
   },
   "source": [
    "### 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QG9wwuN2qneN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Scheduler\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCwqtKCFrbt3"
   },
   "source": [
    "### 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvFwsdlyrVst",
    "outputId": "77d50ad0-4edb-4074-eb9c-cb856d0bb452"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 349/349 [1:07:33<00:00, 11.61s/it, loss=0.00479]\n",
      "Epoch 1: 100%|██████████| 349/349 [1:06:56<00:00, 11.51s/it, loss=0.00644]\n",
      "Epoch 2: 100%|██████████| 349/349 [1:07:41<00:00, 11.64s/it, loss=0.00148]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 3\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        if \"label\" in batch:\n",
    "            batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGz5mOW828lO"
   },
   "source": [
    "### Saving the model After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4EOCEe03Amn",
    "outputId": "bc8dc386-38b7-438f-f737-b69bc9b148e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./spam_model/tokenizer_config.json',\n",
       " './spam_model/special_tokens_map.json',\n",
       " './spam_model/vocab.txt',\n",
       " './spam_model/added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./spam_model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "St0I0lz03NZ4"
   },
   "source": [
    "### To save locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "collapsed": true,
    "id": "9WB4PFIN3QDE",
    "outputId": "417f418d-0d4d-4e0e-c7ac-ace0c036637c"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_4dc5873f-7cfc-40dc-8368-2d032af3cf00\", \"spam_model.zip\", 405694988)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# zip the folder\n",
    "shutil.make_archive(\"spam_model\", 'zip', \"./spam_model\")\n",
    "\n",
    "# download the zip file\n",
    "files.download(\"spam_model.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2qmxgf683VIf"
   },
   "outputs": [],
   "source": [
    "# Reloading the trained Model\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"./spam_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./spam_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq7Q9QzY4XHl"
   },
   "source": [
    "### Uploading the model to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263,
     "referenced_widgets": [
      "db4518cc598b47ffa72dae165e853f0f",
      "3e13b8e6d0874b2089b9e6098b2e79ef",
      "d36561330d754fccab02469ce8e628d2",
      "28a414193f6842308189b54d18840da1",
      "bf6187eb8c7d4ca49135c662c2e2e900",
      "49e27dd02ac6457581e300a0f5572062",
      "c661dc94f84c4497af02d74bcd957919",
      "beb4576a8365486fa00ba4163b57ed9d",
      "a931a9fd8fe14cf19b2a28b76d41e963",
      "0144a8c610da4f3699a7046dfeb50893",
      "203356de3b6b41fa9efea752e849d8b4",
      "99492c59d359430ea5ebbeb72e52c8ee",
      "4f44b7a8495d4fec8a29d0fed7f586c2",
      "0aabe03eb64b427bb375eabc99081ea9",
      "82555ccb7032487d8afba3a3b6d10632",
      "aca91fd0b9174392932bda388541a7e1",
      "8250141920494b02a4796669eab2ec87",
      "911e3d212cd54c25a43c82fbe27f2c3b",
      "51ecbf055e70416386c687e8634db401",
      "9eb66e090bdd48f8b2feea2c651949e6"
     ]
    },
    "collapsed": true,
    "id": "dlWINLmt4fGb",
    "outputId": "77bd3e58-c36a-48b9-ca0a-2dce1f157422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.8.3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4518cc598b47ffa72dae165e853f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAlFvTIx4z9k"
   },
   "source": [
    "### Push the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "bd215e21cdda487aaf871858aaf4b3a5",
      "fef466cb231a479baaf73fb125480ed8",
      "aa0d8ff818d344d6bf297400db3b5320",
      "62d8f0518b544dd8b63dd66da2f8ea31",
      "20a93aba397b46fc89067319d356f75a",
      "09c915efbe0a46078ad51980409cb7c0",
      "849931ebbd5647809a145df9f7dfaac8",
      "aaf2dd1293ed4c15b1d8819455eaeab4",
      "d1afb94f9dd04f3da528f715a2cd8a29",
      "7920b3c0a0cf41d7bd483ddcbe1951df",
      "8d43a7a6298a48e58b8d64468d2922ee",
      "db9872bd977f4adba19071b2ef5ed79b",
      "d51b05cfbf2b40aa9e6476232f836c3c",
      "d5d04865d048464eb084cd58b3f70fd2",
      "9f5ec541667849f587d0f2ef3b50380f",
      "4d1c71b834ee4944b1556e6f08d3539b",
      "e124edf872c7457db5ceb6f8c3ee36a6",
      "6d39d47f536a42e79df21dd38e59bf7f",
      "610ba4ebc1aa4f368cc6c6e11dff9f4d",
      "4076dfcfda0d469e934d25090e9534b3",
      "ec18c3444bb04e22b25e203b12df85c7",
      "047c494b707d45c682512fa1c45afee4",
      "2aefd558632c4ea9beb3c6382cb72abd",
      "7878988183e04257a75feb7546a837ad",
      "d80e57238746459da5e6d1563c890c45",
      "d2c0212ef2ee44429309bbeee51f0428",
      "22f6407edd4c49a6ad8ca2277bc37bc9",
      "e2f8bfc611aa496180c81c9876e963f2",
      "5ceae059110d46a6811b20911cc1ef5b",
      "eaad93a5d81b4dd5b0038b46281008fc",
      "4f984edda8d94c7aa60cbc638d94dedf",
      "2ae40236de064380acc0003674c9d00c",
      "5b5957d3b89f42a2832344e12a5cbae5",
      "dfccc8a39abc421db5d1f4824053374f",
      "bac4ce21c6b94b9fa5d7cce0c77930ef",
      "b337251ea953429eb82e43d56dfe6ed6",
      "206d39bf1b434140b1cecb44180a2ccc",
      "f4725d8e05da47dd98a2eeb891d38e6e",
      "c1293d4232e346edae12fdfa483b860e",
      "614129996d144fa39bc03274da3a8c09",
      "d3dd9e9ac1b44a20821f379a46576f23",
      "4945fbfb1cb543fb9d3545b8e46d7e04",
      "db3c0da0ee5643a9befd58090e5fbe0e",
      "02d482c474de4d2c9af67cc272e4ef7b"
     ]
    },
    "id": "TQgD-wEJ411a",
    "outputId": "3b42fe30-5673-4935-b98a-235a810aa9b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd215e21cdda487aaf871858aaf4b3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9872bd977f4adba19071b2ef5ed79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aefd558632c4ea9beb3c6382cb72abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  /tmp/tmpvu5r2hgx/model.safetensors    :   0%|          | 14.2kB /  438MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfccc8a39abc421db5d1f4824053374f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ssarathi/bert-spam-classifier/commit/02a1cbdd0309734618d529a45b21fd2e5723efe7', commit_message='Upload tokenizer', commit_description='', oid='02a1cbdd0309734618d529a45b21fd2e5723efe7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ssarathi/bert-spam-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='ssarathi/bert-spam-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder, Repository, create_repo\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Create a new repo on Hugging Face Hub (only first time)\n",
    "repo_name = \"bert-spam-classifier\"   # choose a unique name\n",
    "create_repo(repo_name, exist_ok=True)\n",
    "\n",
    "# Push your model to hub\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbQfaqnr48vl"
   },
   "source": [
    "### Loading the model anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "a62123526879413a85e3c04a39a1705e",
      "511bad483b4540fdabcd33d6e04574d9",
      "78cc43ba42e44c5aab452d9acfe16dc8",
      "86af1f46e8db42ffbcf3c0bdd62deed5",
      "be70d795603d48a897e6a20a549fa7b3",
      "efc1be02a5134fbfa95442cfbcafcc1e",
      "d97fb4a7f54c4fa29a001c02f6426938",
      "dc9d93ee510d4d53b7b65b7ca4cb1277",
      "66b4e4fc03f44f0dbf30be266a258528",
      "72a6ebad2dcc40f4b3d876a216ab330d",
      "5ef43dee4ad64aef8987bcad7d1c7436",
      "96ca336539434ea1a2249f4731da7081",
      "049d4c9b71104a47bfecdbbbb67bfe4d",
      "5765352004a8499c82c205bb4b79d2fb",
      "4692f7d213684ef0a74f4040603810a7",
      "c5f2c38b31a14cef9e1f1545d08d9a48",
      "f74124b20dff48c08093cc8e4887ac7f",
      "73bac5de7512413f9eaf1b16ad055b2c",
      "4083645f71d24b3eb31674ec3b423a86",
      "b429f92b068047fe830e2c78f6b3d902",
      "b8d1c39902c142e99dbe8a1a6df7ca1e",
      "14b2fd8420c043928be32cc4849a8ccc",
      "c30a4d0722e74e349e334e16c69d375c",
      "7b392681a61a42c5b0f741a771e64a06",
      "9617c25aab354e64a2affc24235202bf",
      "b3fba37c51d74a6487ada0959d107512",
      "24c92270bd774ab6806c5de3c07c0a1e",
      "cf13aeb2ebdc402dbdba0feb2d6e99e6",
      "e6ef8a1ebec44310b552fc24d290e518",
      "2ec73ea1b488491080d268fa5c8cd1ed",
      "3c556650c5e0408480a8871d8143362e",
      "83d881237475401097a598dcf787a35e",
      "aeb7ccf6634942dbab940f5da75383ec",
      "3df6f99fc2344a59994f3c060505bf71",
      "cdc344d00b5f4cf08be2d959c84971ba",
      "5cd92e8c33c1420880b692afd88912be",
      "93e24b9a4abf4b1da6888a6a0dbabc9e",
      "915ea1cf81d54b64b249a357d5638d4d",
      "380e0e818f5042af800751639f050689",
      "1f59d157cb8144c891c497c637740057",
      "691c80137bbb4a2db2a77cb6c6ca291f",
      "d73d46d94dbf4164a69d5b26d64ab105",
      "d2770a1ad5524000aa67bd1837dfd64b",
      "ab5652ec47e347068b606d3b72bef67e",
      "de49315889e84ef29bab4c0d2940fda2",
      "8b2012898784444fa6ab21c50e739ff3",
      "044a0ac1d0f84bc1bb5a676a8ed1c34e",
      "cf40aa7e3a0f465c93fb5a94e5b18089",
      "4ce18b7c5a1e413896cb41c89249cae3",
      "306285e900e94ca1a6bc9d23041bbc34",
      "97093cbc3d324a2d8f36a72aed76ed3d",
      "3dcc6d05ea2c42af8d827f00a80ae8d3",
      "7643aafb927e48a5a7604d44c8a9d17e",
      "b9c95b8891ae4760b9da50f17b76d423",
      "f9b576bca9534c85a2f98775db3a8bbc"
     ]
    },
    "id": "Tom3T83i5Baz",
    "outputId": "75d99298-a7fd-4ccb-e7a0-acf1f7c3abcc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62123526879413a85e3c04a39a1705e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ca336539434ea1a2249f4731da7081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30a4d0722e74e349e334e16c69d375c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df6f99fc2344a59994f3c060505bf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de49315889e84ef29bab4c0d2940fda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"ssarathi/bert-spam-classifier\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ssarathi/bert-spam-classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utoPvbeDsjG4"
   },
   "source": [
    "### 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "oMvYZUI9rdfz",
    "outputId": "7326ebf7-bec2-4425-a3ca-753898af1760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996411912450663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "preds, labels = [], []\n",
    "\n",
    "for batch in train_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    # Rename 'label' to 'labels' before passing to model\n",
    "    batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    preds.extend(predictions.cpu().numpy())\n",
    "    labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(labels, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5cs7tsxbvGj"
   },
   "source": [
    "### Reloading the model for inference on new set of Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oihfaPY4UDTL",
    "outputId": "b0e3bd81-9d2b-43df-b7ae-e1644a96a2e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model_path = \"ssarathi/bert-spam-classifier\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, use_safetensors=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()  # set model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q35Ob1fdFZo"
   },
   "source": [
    "### Tokenize new Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "IZo2zE_cdUgz"
   },
   "outputs": [],
   "source": [
    "new_emails = [\n",
    "    \"Congratulations! You won a free iPhone. Click here to claim.\",\n",
    "    \"Hi team, please find the report attached for your review.\",\n",
    "    \"Earn $5000 per week from home, no experience required!\",\n",
    "    \"Meet me at 10pm tonight in Urban Square\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "fK6f41xqb71z"
   },
   "outputs": [],
   "source": [
    "# Tokenize batch of emails\n",
    "inputs = tokenizer(\n",
    "    new_emails,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uzh0XGtLdHkH",
    "outputId": "8ae62ca9-2d5e-492d-bd0c-22a5e5710160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: Congratulations! You won a free iPhone. Click here to claim.\n",
      "Prediction: spam\n",
      "\n",
      "Email: Hi team, please find the report attached for your review.\n",
      "Prediction: ham\n",
      "\n",
      "Email: Earn $5000 per week from home, no experience required!\n",
      "Prediction: spam\n",
      "\n",
      "Email: Meet me at 10pm tonight in Urban Square\n",
      "Prediction: ham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Convert predictions to labels (adjust based on your training)\n",
    "label_map = {0: \"ham\", 1: \"spam\"}  # assuming 0 = ham, 1 = spam\n",
    "predicted_labels = [label_map[p.item()] for p in predictions]\n",
    "\n",
    "# Show results\n",
    "for email, label in zip(new_emails, predicted_labels):\n",
    "    print(f\"Email: {email}\\nPrediction: {label}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
